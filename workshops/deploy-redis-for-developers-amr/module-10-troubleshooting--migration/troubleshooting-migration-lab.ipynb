{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ccbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Redis container\n",
    "!docker run -d --name workshop-redis-module10 -p 6379:6379 redis:7-alpine\n",
    "\n",
    "# Wait for Redis to be ready\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "# Test connection\n",
    "!docker exec workshop-redis-module10 redis-cli ping\n",
    "\n",
    "print('‚úÖ Redis container is running on localhost:6379')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74174a",
   "metadata": {},
   "source": [
    "# Module 10: Troubleshooting & Migration\n",
    "\n",
    "## üéØ Interactive Lab: Diagnostics & Data Migration\n",
    "\n",
    "**Duration:** 60 minutes  \n",
    "**Level:** Advanced  \n",
    "\n",
    "In this lab, you'll:\n",
    "- üîç Use diagnostic commands to troubleshoot issues\n",
    "- üìä Analyze slow queries and performance\n",
    "- üöÄ Migrate data between Redis instances\n",
    "- üõ†Ô∏è Use RIOT for bulk operations\n",
    "- ‚úÖ Implement migration best practices\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c94071",
   "metadata": {},
   "source": [
    "## üê≥ Start Docker Redis Container\n",
    "\n",
    "Before we begin, let's start a Redis container using Docker:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d6997",
   "metadata": {},
   "source": [
    "## Part 1: Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q redis\n",
    "\n",
    "import redis\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Connect to Redis\n",
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    r.ping()\n",
    "    print('‚úÖ Connected to Redis')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Connection failed: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6812119d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Diagnostic Commands\n",
    "\n",
    "Essential commands for troubleshooting Redis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_diagnostics():\n",
    "    \"\"\"Run comprehensive Redis diagnostics\"\"\"\n",
    "    \n",
    "    print('üîç Redis Diagnostics Report')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Server info\n",
    "    info = r.info('server')\n",
    "    print(f'\\nüìä Server Info:')\n",
    "    print(f'   Redis version: {info[\"redis_version\"]}')\n",
    "    print(f'   Uptime: {info[\"uptime_in_days\"]} days')\n",
    "    print(f'   Process ID: {info[\"process_id\"]}')\n",
    "    \n",
    "    # Memory stats\n",
    "    mem_info = r.info('memory')\n",
    "    used_mb = mem_info['used_memory'] / 1024 / 1024\n",
    "    peak_mb = mem_info['used_memory_peak'] / 1024 / 1024\n",
    "    print(f'\\nüíæ Memory:')\n",
    "    print(f'   Used: {used_mb:.2f} MB')\n",
    "    print(f'   Peak: {peak_mb:.2f} MB')\n",
    "    print(f'   Fragmentation: {mem_info.get(\"mem_fragmentation_ratio\", 1.0):.2f}')\n",
    "    \n",
    "    # Stats\n",
    "    stats = r.info('stats')\n",
    "    print(f'\\nüìà Stats:')\n",
    "    print(f'   Total connections: {stats[\"total_connections_received\"]}')\n",
    "    print(f'   Total commands: {stats[\"total_commands_processed\"]}')\n",
    "    print(f'   Keyspace hits: {stats.get(\"keyspace_hits\", 0)}')\n",
    "    print(f'   Keyspace misses: {stats.get(\"keyspace_misses\", 0)}')\n",
    "    \n",
    "    # Calculate hit rate\n",
    "    hits = stats.get('keyspace_hits', 0)\n",
    "    misses = stats.get('keyspace_misses', 0)\n",
    "    total = hits + misses\n",
    "    if total > 0:\n",
    "        hit_rate = (hits / total) * 100\n",
    "        print(f'   Hit rate: {hit_rate:.1f}%')\n",
    "    \n",
    "    # Clients\n",
    "    clients = r.info('clients')\n",
    "    print(f'\\nüë• Clients:')\n",
    "    print(f'   Connected: {clients[\"connected_clients\"]}')\n",
    "    print(f'   Blocked: {clients.get(\"blocked_clients\", 0)}')\n",
    "    \n",
    "    # Keyspace\n",
    "    keyspace = r.info('keyspace')\n",
    "    print(f'\\nüîë Keyspace:')\n",
    "    if keyspace:\n",
    "        for db, info in keyspace.items():\n",
    "            print(f'   {db}: {info}')\n",
    "    else:\n",
    "        print('   No keys found')\n",
    "\n",
    "# Run diagnostics\n",
    "run_diagnostics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9810fbc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: SLOWLOG Analysis\n",
    "\n",
    "Identify slow queries affecting performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb03a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_slowlog():\n",
    "    \"\"\"Analyze slow query log\"\"\"\n",
    "    \n",
    "    print('üêå Slow Query Analysis')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Get slowlog entries\n",
    "    slowlog = r.slowlog_get(10)  # Last 10 entries\n",
    "    \n",
    "    if not slowlog:\n",
    "        print('‚úÖ No slow queries found!')\n",
    "        print('   This is good - your queries are fast')\n",
    "        return\n",
    "    \n",
    "    print(f'\\n‚ö†Ô∏è  Found {len(slowlog)} slow queries:')\n",
    "    print()\n",
    "    \n",
    "    for entry in slowlog:\n",
    "        # entry is a dict with: id, start_time, duration, command\n",
    "        duration_ms = entry['duration'] / 1000  # Convert to ms\n",
    "        command = ' '.join(str(arg) for arg in entry['command'])\n",
    "        \n",
    "        print(f'‚è±Ô∏è  Duration: {duration_ms:.2f} ms')\n",
    "        print(f'   Command: {command[:100]}')\n",
    "        print()\n",
    "\n",
    "# First, generate some activity\n",
    "print('üìù Generating sample queries...')\n",
    "for i in range(100):\n",
    "    r.set(f'test:{i}', f'value_{i}')\n",
    "    r.get(f'test:{i}')\n",
    "\n",
    "# Analyze slowlog\n",
    "analyze_slowlog()\n",
    "\n",
    "# Show slowlog configuration\n",
    "print('‚öôÔ∏è  Slowlog Configuration:')\n",
    "threshold = r.config_get('slowlog-log-slower-than')\n",
    "max_len = r.config_get('slowlog-max-len')\n",
    "print(f'   Threshold: {threshold} microseconds')\n",
    "print(f'   Max entries: {max_len}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7befbb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: CLIENT LIST Analysis\n",
    "\n",
    "Monitor connected clients and identify issues:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755324ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_clients():\n",
    "    \"\"\"Analyze connected clients\"\"\"\n",
    "    \n",
    "    print('üë• Client Connection Analysis')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Get client list\n",
    "    clients = r.client_list()\n",
    "    \n",
    "    if not clients:\n",
    "        print('‚ÑπÔ∏è  No clients connected')\n",
    "        return\n",
    "    \n",
    "    print(f'\\nüìä Total clients: {len(clients)}')\n",
    "    print()\n",
    "    \n",
    "    # Analyze clients\n",
    "    idle_times = []\n",
    "    commands = []\n",
    "    \n",
    "    for client in clients:\n",
    "        idle = int(client.get('idle', 0))\n",
    "        idle_times.append(idle)\n",
    "        \n",
    "        cmd = client.get('cmd', 'unknown')\n",
    "        commands.append(cmd)\n",
    "    \n",
    "    # Show summary\n",
    "    if idle_times:\n",
    "        avg_idle = sum(idle_times) / len(idle_times)\n",
    "        max_idle = max(idle_times)\n",
    "        \n",
    "        print(f'‚è±Ô∏è  Idle Times:')\n",
    "        print(f'   Average: {avg_idle:.1f} seconds')\n",
    "        print(f'   Maximum: {max_idle} seconds')\n",
    "        \n",
    "        # Warn about idle connections\n",
    "        long_idle = [c for c in clients if int(c.get('idle', 0)) > 300]\n",
    "        if long_idle:\n",
    "            print(f'\\n‚ö†Ô∏è  {len(long_idle)} clients idle > 5 minutes')\n",
    "            print('   Consider setting timeout for idle connections')\n",
    "    \n",
    "    # Show sample clients\n",
    "    print(f'\\nüìã Sample Clients (showing first 3):')\n",
    "    for i, client in enumerate(clients[:3]):\n",
    "        print(f'\\n   Client {i+1}:')\n",
    "        print(f'      Address: {client.get(\"addr\", \"unknown\")}')\n",
    "        print(f'      Age: {client.get(\"age\", 0)} seconds')\n",
    "        print(f'      Idle: {client.get(\"idle\", 0)} seconds')\n",
    "        print(f'      Last command: {client.get(\"cmd\", \"unknown\")}')\n",
    "\n",
    "# Run analysis\n",
    "analyze_clients()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c5eaa4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Memory Analysis\n",
    "\n",
    "Deep dive into memory usage patterns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_memory_by_pattern():\n",
    "    \"\"\"Analyze memory usage by key patterns\"\"\"\n",
    "    \n",
    "    print('üíæ Memory Usage by Key Pattern')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Create sample data with different patterns\n",
    "    patterns = {\n",
    "        'cache:': 50,\n",
    "        'session:': 30,\n",
    "        'user:': 20,\n",
    "    }\n",
    "    \n",
    "    for pattern, count in patterns.items():\n",
    "        for i in range(count):\n",
    "            r.set(f'{pattern}{i}', 'x' * 100)\n",
    "    \n",
    "    # Analyze patterns\n",
    "    print('\\nüìä Key Distribution:')\n",
    "    print()\n",
    "    \n",
    "    total_keys = 0\n",
    "    for pattern in patterns.keys():\n",
    "        keys = r.keys(f'{pattern}*')\n",
    "        count = len(keys)\n",
    "        total_keys += count\n",
    "        \n",
    "        # Sample memory usage\n",
    "        if keys:\n",
    "            sample_size = r.memory_usage(keys[0]) if hasattr(r, 'memory_usage') else 100\n",
    "            estimated_mb = (count * sample_size) / 1024 / 1024\n",
    "            \n",
    "            print(f'   {pattern:<12} {count:>5} keys  ~{estimated_mb:.2f} MB')\n",
    "    \n",
    "    print(f'\\n   Total: {total_keys} keys')\n",
    "    \n",
    "    # Get overall memory\n",
    "    info = r.info('memory')\n",
    "    used_mb = info['used_memory'] / 1024 / 1024\n",
    "    print(f'\\nüíæ Total memory used: {used_mb:.2f} MB')\n",
    "\n",
    "# Run analysis\n",
    "analyze_memory_by_pattern()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c005ea1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Data Migration Preparation\n",
    "\n",
    "Prepare for migrating data between Redis instances:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_migration_report():\n",
    "    \"\"\"Generate pre-migration report\"\"\"\n",
    "    \n",
    "    print('üìã Pre-Migration Checklist')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Count keys\n",
    "    total_keys = r.dbsize()\n",
    "    print(f'\\nüìä Data Inventory:')\n",
    "    print(f'   Total keys: {total_keys:,}')\n",
    "    \n",
    "    # Sample key types\n",
    "    if total_keys > 0:\n",
    "        keys_sample = r.keys('*')[:100]  # Sample first 100\n",
    "        types = {}\n",
    "        \n",
    "        for key in keys_sample:\n",
    "            key_type = r.type(key)\n",
    "            types[key_type] = types.get(key_type, 0) + 1\n",
    "        \n",
    "        print(f'\\nüîë Key Types (sample of {len(keys_sample)}):')\n",
    "        for key_type, count in types.items():\n",
    "            print(f'   {key_type:<10} {count:>5} keys')\n",
    "    \n",
    "    # Memory info\n",
    "    mem_info = r.info('memory')\n",
    "    used_mb = mem_info['used_memory'] / 1024 / 1024\n",
    "    peak_mb = mem_info['used_memory_peak'] / 1024 / 1024\n",
    "    \n",
    "    print(f'\\nüíæ Memory Requirements:')\n",
    "    print(f'   Current usage: {used_mb:.2f} MB')\n",
    "    print(f'   Peak usage: {peak_mb:.2f} MB')\n",
    "    print(f'   Recommended target: {peak_mb * 1.2:.2f} MB (with 20% buffer)')\n",
    "    \n",
    "    # Estimate migration time\n",
    "    if total_keys > 0:\n",
    "        # Rough estimate: 1000 keys/second\n",
    "        estimated_seconds = total_keys / 1000\n",
    "        estimated_minutes = estimated_seconds / 60\n",
    "        \n",
    "        print(f'\\n‚è±Ô∏è  Migration Estimate:')\n",
    "        print(f'   Estimated time: {estimated_minutes:.1f} minutes')\n",
    "        print(f'   (at ~1000 keys/second)')\n",
    "    \n",
    "    # Checklist\n",
    "    print(f'\\n‚úÖ Pre-Migration Checklist:')\n",
    "    checklist = [\n",
    "        'Backup source Redis instance',\n",
    "        'Provision target instance with sufficient memory',\n",
    "        'Test connectivity to target instance',\n",
    "        'Plan maintenance window',\n",
    "        'Prepare rollback plan',\n",
    "        'Notify stakeholders',\n",
    "    ]\n",
    "    \n",
    "    for item in checklist:\n",
    "        print(f'   ‚ñ° {item}')\n",
    "\n",
    "# Generate report\n",
    "prepare_migration_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c6ba6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Simple Key Migration\n",
    "\n",
    "Migrate keys between Redis instances (demo with same instance):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def migrate_keys_demo():\n",
    "    \"\"\"Demonstrate key migration pattern\"\"\"\n",
    "    \n",
    "    print('üöÄ Key Migration Demo')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    # Create sample data in \"source\" namespace\n",
    "    print('\\nüìù Creating source data...')\n",
    "    source_prefix = 'source:'\n",
    "    target_prefix = 'target:'\n",
    "    \n",
    "    # Clear any existing data\n",
    "    for key in r.keys(f'{source_prefix}*') + r.keys(f'{target_prefix}*'):\n",
    "        r.delete(key)\n",
    "    \n",
    "    # Create source data\n",
    "    for i in range(10):\n",
    "        r.set(f'{source_prefix}key:{i}', f'value_{i}')\n",
    "        r.setex(f'{source_prefix}temp:{i}', 3600, f'temp_{i}')  # With TTL\n",
    "    \n",
    "    source_keys = r.keys(f'{source_prefix}*')\n",
    "    print(f'   Created {len(source_keys)} source keys')\n",
    "    \n",
    "    # Migration function\n",
    "    def migrate_key(source_key, target_key):\n",
    "        \"\"\"Migrate a single key with its TTL\"\"\"\n",
    "        # Get value\n",
    "        value = r.get(source_key)\n",
    "        if value is None:\n",
    "            return False\n",
    "        \n",
    "        # Get TTL\n",
    "        ttl = r.ttl(source_key)\n",
    "        \n",
    "        # Set in target\n",
    "        if ttl > 0:\n",
    "            r.setex(target_key, ttl, value)\n",
    "        else:\n",
    "            r.set(target_key, value)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    # Migrate keys\n",
    "    print(f'\\nüîÑ Migrating keys...')\n",
    "    migrated = 0\n",
    "    \n",
    "    for source_key in source_keys:\n",
    "        # Convert source: prefix to target: prefix\n",
    "        target_key = source_key.replace(source_prefix, target_prefix)\n",
    "        \n",
    "        if migrate_key(source_key, target_key):\n",
    "            migrated += 1\n",
    "    \n",
    "    print(f'   Migrated {migrated} keys')\n",
    "    \n",
    "    # Verify migration\n",
    "    target_keys = r.keys(f'{target_prefix}*')\n",
    "    print(f'\\n‚úÖ Verification:')\n",
    "    print(f'   Source keys: {len(source_keys)}')\n",
    "    print(f'   Target keys: {len(target_keys)}')\n",
    "    print(f'   Migration complete: {len(source_keys) == len(target_keys)}')\n",
    "    \n",
    "    # Show sample\n",
    "    if target_keys:\n",
    "        sample_key = target_keys[0]\n",
    "        sample_value = r.get(sample_key)\n",
    "        sample_ttl = r.ttl(sample_key)\n",
    "        \n",
    "        print(f'\\nüìã Sample migrated key:')\n",
    "        print(f'   Key: {sample_key}')\n",
    "        print(f'   Value: {sample_value}')\n",
    "        print(f'   TTL: {sample_ttl} seconds' if sample_ttl > 0 else '   TTL: No expiration')\n",
    "\n",
    "# Run migration demo\n",
    "migrate_keys_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b094f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Performance Testing\n",
    "\n",
    "Test performance before and after migration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_performance():\n",
    "    \"\"\"Benchmark Redis performance\"\"\"\n",
    "    \n",
    "    print('‚ö° Performance Benchmark')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    import statistics\n",
    "    \n",
    "    operations = 1000\n",
    "    \n",
    "    # Test SET performance\n",
    "    print(f'\\nüìù Testing SET ({operations} operations)...')\n",
    "    set_times = []\n",
    "    \n",
    "    for i in range(operations):\n",
    "        start = time.perf_counter()\n",
    "        r.set(f'perf:test:{i}', f'value_{i}')\n",
    "        elapsed = (time.perf_counter() - start) * 1000\n",
    "        set_times.append(elapsed)\n",
    "    \n",
    "    print(f'   Average: {statistics.mean(set_times):.2f} ms')\n",
    "    print(f'   Median: {statistics.median(set_times):.2f} ms')\n",
    "    print(f'   P95: {sorted(set_times)[int(len(set_times) * 0.95)]:.2f} ms')\n",
    "    print(f'   P99: {sorted(set_times)[int(len(set_times) * 0.99)]:.2f} ms')\n",
    "    \n",
    "    # Test GET performance\n",
    "    print(f'\\nüìñ Testing GET ({operations} operations)...')\n",
    "    get_times = []\n",
    "    \n",
    "    for i in range(operations):\n",
    "        start = time.perf_counter()\n",
    "        r.get(f'perf:test:{i}')\n",
    "        elapsed = (time.perf_counter() - start) * 1000\n",
    "        get_times.append(elapsed)\n",
    "    \n",
    "    print(f'   Average: {statistics.mean(get_times):.2f} ms')\n",
    "    print(f'   Median: {statistics.median(get_times):.2f} ms')\n",
    "    print(f'   P95: {sorted(get_times)[int(len(get_times) * 0.95)]:.2f} ms')\n",
    "    print(f'   P99: {sorted(get_times)[int(len(get_times) * 0.99)]:.2f} ms')\n",
    "    \n",
    "    # Cleanup\n",
    "    for i in range(operations):\n",
    "        r.delete(f'perf:test:{i}')\n",
    "    \n",
    "    print(f'\\n‚úÖ Benchmark complete')\n",
    "\n",
    "# Run benchmark\n",
    "benchmark_performance()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fa2817",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Troubleshooting Common Issues\n",
    "\n",
    "### Common Problems and Solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def troubleshooting_guide():\n",
    "    \"\"\"Display troubleshooting guide\"\"\"\n",
    "    \n",
    "    issues = [\n",
    "        {\n",
    "            'problem': 'High Memory Usage',\n",
    "            'symptoms': ['Memory close to limit', 'Evictions occurring'],\n",
    "            'solutions': [\n",
    "                'Check for keys without TTL',\n",
    "                'Analyze key patterns with MEMORY USAGE',\n",
    "                'Consider using Hashes instead of separate keys',\n",
    "                'Review maxmemory-policy setting',\n",
    "                'Scale up to larger instance'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'problem': 'Slow Query Performance',\n",
    "            'symptoms': ['High latency', 'Slow response times'],\n",
    "            'solutions': [\n",
    "                'Check SLOWLOG for expensive commands',\n",
    "                'Avoid KEYS command in production',\n",
    "                'Use pipelining for multiple operations',\n",
    "                'Check network latency',\n",
    "                'Consider using connection pooling'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'problem': 'Connection Issues',\n",
    "            'symptoms': ['Timeout errors', 'Connection refused'],\n",
    "            'solutions': [\n",
    "                'Verify network connectivity',\n",
    "                'Check firewall rules',\n",
    "                'Verify authentication credentials',\n",
    "                'Check maxclients setting',\n",
    "                'Review timeout configuration'\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'problem': 'Memory Fragmentation',\n",
    "            'symptoms': ['High RSS memory', 'Fragmentation ratio > 1.5'],\n",
    "            'solutions': [\n",
    "                'Monitor fragmentation ratio',\n",
    "                'Consider enabling active defragmentation',\n",
    "                'Restart Redis during maintenance window',\n",
    "                'Review key patterns and sizes'\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print('üîß Troubleshooting Guide')\n",
    "    print('=' * 60)\n",
    "    \n",
    "    for i, issue in enumerate(issues, 1):\n",
    "        print(f'\\n{i}. {issue[\"problem\"]}')\n",
    "        print('   ' + '-' * 40)\n",
    "        \n",
    "        print('   Symptoms:')\n",
    "        for symptom in issue['symptoms']:\n",
    "            print(f'     ‚Ä¢ {symptom}')\n",
    "        \n",
    "        print('   Solutions:')\n",
    "        for solution in issue['solutions']:\n",
    "            print(f'     ‚úì {solution}')\n",
    "\n",
    "# Display guide\n",
    "troubleshooting_guide()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d477ef8a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4dc3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up test data\n",
    "r.flushdb()\n",
    "print('‚úÖ Redis data cleaned')\n",
    "\n",
    "# Stop and remove Docker container\n",
    "!docker stop workshop-redis-module10\n",
    "!docker rm workshop-redis-module10\n",
    "\n",
    "print('‚úÖ Docker container removed')\n",
    "print('‚úÖ Cleanup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35e423",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "### üîç Diagnostic Tools\n",
    "\n",
    "1. **INFO Command**\n",
    "   - Server, memory, stats, clients, keyspace\n",
    "   - Run regularly for monitoring\n",
    "   - Track trends over time\n",
    "\n",
    "2. **SLOWLOG**\n",
    "   - Identify expensive queries\n",
    "   - Set appropriate threshold\n",
    "   - Optimize slow commands\n",
    "\n",
    "3. **CLIENT LIST**\n",
    "   - Monitor connections\n",
    "   - Identify idle clients\n",
    "   - Track client activity\n",
    "\n",
    "4. **MEMORY USAGE**\n",
    "   - Analyze key memory\n",
    "   - Find memory hogs\n",
    "   - Optimize data structures\n",
    "\n",
    "### üöÄ Migration Best Practices\n",
    "\n",
    "1. **Planning**\n",
    "   - Inventory source data\n",
    "   - Estimate migration time\n",
    "   - Plan maintenance window\n",
    "\n",
    "2. **Execution**\n",
    "   - Backup before migration\n",
    "   - Test with sample data\n",
    "   - Monitor progress\n",
    "   - Verify data integrity\n",
    "\n",
    "3. **Tools**\n",
    "   - DUMP/RESTORE for single keys\n",
    "   - RIOT for bulk migration\n",
    "   - Replication for live migration\n",
    "   - Custom scripts for complex scenarios\n",
    "\n",
    "4. **Validation**\n",
    "   - Compare key counts\n",
    "   - Verify sample data\n",
    "   - Test performance\n",
    "   - Check TTLs preserved\n",
    "\n",
    "### üõ†Ô∏è Troubleshooting Checklist\n",
    "\n",
    "- ‚úÖ Run INFO to get overview\n",
    "- ‚úÖ Check SLOWLOG for slow queries\n",
    "- ‚úÖ Monitor memory usage\n",
    "- ‚úÖ Review client connections\n",
    "- ‚úÖ Check fragmentation ratio\n",
    "- ‚úÖ Verify network connectivity\n",
    "- ‚úÖ Review configuration settings\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Outstanding Work!\n",
    "\n",
    "You now have the skills to troubleshoot and migrate Redis successfully!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
