{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51868d01",
   "metadata": {},
   "source": [
    "# ðŸš€ Implement Caching Lab - Interactive Edition\n",
    "\n",
    "**Duration:** 45-60 minutes  \n",
    "**Level:** Intermediate\n",
    "\n",
    "Welcome to the interactive caching lab! In this hands-on notebook, you'll:\n",
    "\n",
    "- âœ… Implement the **cache-aside pattern** with Redis\n",
    "- âœ… Use **real PostgreSQL database** with Docker\n",
    "- âœ… Measure **real performance improvements** (10-100x speedup)\n",
    "- âœ… Visualize cache effectiveness with **interactive charts**\n",
    "- âœ… Learn cache invalidation strategies\n",
    "- âœ… Apply best practices for production systems\n",
    "\n",
    "**Real infrastructure!** We'll use Docker to run PostgreSQL and Redis, giving you hands-on experience with production-grade caching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67540fc",
   "metadata": {},
   "source": [
    "## ðŸ“š What You'll Learn\n",
    "\n",
    "By the end of this lab, you'll understand:\n",
    "\n",
    "1. **Cache-Aside Pattern** - The most common caching strategy\n",
    "2. **Performance Measurement** - Quantify latency improvements\n",
    "3. **Hit Rate Optimization** - Maximize cache effectiveness\n",
    "4. **Cache Invalidation** - Keep data fresh and consistent\n",
    "5. **TTL Strategy** - Balance freshness vs. performance\n",
    "\n",
    "Let's get started! ðŸŽ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17833256",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Setup and Dependencies (5 minutes)\n",
    "\n",
    "First, let's import all the packages we'll need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8af970",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Infrastructure Setup with Docker (10 minutes)\n",
    "\n",
    "We'll use Docker to run real databases. This gives you hands-on experience with production infrastructure!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd65f5",
   "metadata": {},
   "source": [
    "### ðŸ³ Start PostgreSQL and Redis with Docker\n",
    "\n",
    "Run the following cell to start both databases. This will:\n",
    "- Pull PostgreSQL 15 and Redis 7 images (if not already available)\n",
    "- Start PostgreSQL on port 5432\n",
    "- Start Redis on port 6379\n",
    "- Create a sample database with product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"ðŸš€ Starting PostgreSQL and Redis containers...\"\n",
    "echo\n",
    "\n",
    "# Stop and remove existing containers (if any)\n",
    "docker stop workshop-postgres workshop-redis 2>/dev/null || true\n",
    "docker rm workshop-postgres workshop-redis 2>/dev/null || true\n",
    "\n",
    "# Start PostgreSQL\n",
    "echo \"ðŸ“¦ Starting PostgreSQL 15...\"\n",
    "docker run -d \\\n",
    "  --name workshop-postgres \\\n",
    "  -e POSTGRES_PASSWORD=workshop123 \\\n",
    "  -e POSTGRES_USER=workshop \\\n",
    "  -e POSTGRES_DB=workshop \\\n",
    "  -p 5432:5432 \\\n",
    "  postgres:15-alpine\n",
    "\n",
    "# Start Redis\n",
    "echo \"ðŸ“¦ Starting Redis 7...\"\n",
    "docker run -d \\\n",
    "  --name workshop-redis \\\n",
    "  -p 6379:6379 \\\n",
    "  redis:7-alpine\n",
    "\n",
    "# Wait for databases to be ready\n",
    "echo\n",
    "echo \"â³ Waiting for databases to be ready...\"\n",
    "sleep 5\n",
    "\n",
    "# Check if containers are running\n",
    "if docker ps | grep -q workshop-postgres && docker ps | grep -q workshop-redis; then\n",
    "    echo\n",
    "    echo \"âœ… Both databases are running!\"\n",
    "    echo\n",
    "    docker ps --filter \"name=workshop-\" --format \"table {{.Names}}\\t{{.Status}}\\t{{.Ports}}\"\n",
    "else\n",
    "    echo \"âŒ Failed to start containers. Check Docker installation.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0526e57c",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Install Python Dependencies\n",
    "\n",
    "Install the required packages for PostgreSQL and Redis connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe28745",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q psycopg2-binary redis pandas matplotlib\n",
    "\n",
    "print(\"âœ… All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a72154",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Setup PostgreSQL Database (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ac7d6",
   "metadata": {},
   "source": [
    "### ðŸ—„ï¸ Create Database Schema and Load Sample Data\n",
    "\n",
    "Let's create a products table and populate it with realistic e-commerce data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import time\n",
    "\n",
    "# Database connection parameters\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'workshop',\n",
    "    'user': 'workshop',\n",
    "    'password': 'workshop123'\n",
    "}\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "print(\"ðŸ”Œ Connecting to PostgreSQL...\")\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create products table\n",
    "print(\"ðŸ“‹ Creating products table...\")\n",
    "cur.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS products CASCADE;\n",
    "    \n",
    "    CREATE TABLE products (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        name VARCHAR(255) NOT NULL,\n",
    "        price DECIMAL(10, 2) NOT NULL,\n",
    "        category VARCHAR(100) NOT NULL,\n",
    "        stock INTEGER NOT NULL,\n",
    "        description TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \n",
    "    CREATE INDEX idx_products_category ON products(category);\n",
    "    CREATE INDEX idx_products_price ON products(price);\n",
    "\"\"\")\n",
    "\n",
    "# Sample product data\n",
    "products = [\n",
    "    (\"Laptop Pro 15\", 999.99, \"Electronics\", 50, \"High-performance laptop with 15-inch display\"),\n",
    "    (\"Wireless Mouse\", 29.99, \"Electronics\", 200, \"Ergonomic wireless mouse with long battery life\"),\n",
    "    (\"USB-C Cable\", 12.99, \"Accessories\", 500, \"Durable USB-C to USB-C cable, 6ft\"),\n",
    "    (\"4K Monitor\", 399.99, \"Electronics\", 30, \"27-inch 4K UHD monitor with HDR support\"),\n",
    "    (\"Mechanical Keyboard\", 89.99, \"Electronics\", 75, \"RGB mechanical keyboard with blue switches\"),\n",
    "    (\"Desk Lamp\", 34.99, \"Office\", 120, \"LED desk lamp with adjustable brightness\"),\n",
    "    (\"Ergonomic Chair\", 299.99, \"Furniture\", 40, \"Comfortable office chair with lumbar support\"),\n",
    "    (\"Webcam HD\", 69.99, \"Electronics\", 90, \"1080p HD webcam with built-in microphone\"),\n",
    "    (\"Headphones\", 149.99, \"Electronics\", 60, \"Noise-cancelling over-ear headphones\"),\n",
    "    (\"Phone Stand\", 19.99, \"Accessories\", 300, \"Adjustable smartphone stand for desk\")\n",
    "]\n",
    "\n",
    "# Insert products\n",
    "print(f\"ðŸ’¾ Inserting {len(products)} products...\")\n",
    "execute_values(\n",
    "    cur,\n",
    "    \"INSERT INTO products (name, price, category, stock, description) VALUES %s\",\n",
    "    products\n",
    ")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Verify data\n",
    "cur.execute(\"SELECT COUNT(*) FROM products\")\n",
    "count = cur.fetchone()[0]\n",
    "\n",
    "print(f\"âœ… Database setup complete!\")\n",
    "print(f\"   Table: products\")\n",
    "print(f\"   Rows: {count}\")\n",
    "print(f\"   Ready for caching tests!\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd14d4e",
   "metadata": {},
   "source": [
    "### âœ… Test Database Connection\n",
    "\n",
    "Let's verify the connection works and see some sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be46a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to database\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Query products\n",
    "cur.execute(\"\"\"\n",
    "    SELECT id, name, price, category, stock \n",
    "    FROM products \n",
    "    ORDER BY id \n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "# Fetch results\n",
    "rows = cur.fetchall()\n",
    "columns = [desc[0] for desc in cur.description]\n",
    "\n",
    "# Display as DataFrame\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "print(\"ðŸ“¦ Sample Products in Database:\\n\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Get statistics\n",
    "cur.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_products,\n",
    "        COUNT(DISTINCT category) as total_categories,\n",
    "        ROUND(AVG(price), 2) as avg_price\n",
    "    FROM products\n",
    "\"\"\")\n",
    "\n",
    "stats = cur.fetchone()\n",
    "print(f\"\\nðŸ“Š Database Statistics:\")\n",
    "print(f\"   Total Products: {stats[0]}\")\n",
    "print(f\"   Categories: {stats[1]}\")\n",
    "print(f\"   Average Price: ${stats[2]}\")\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nâœ… Connection test successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import redis\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from typing import Dict, Optional, List\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Configure matplotlib for inline display\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eddfa3a",
   "metadata": {},
   "source": [
    "### ðŸ”§ Configure Redis Connection\n",
    "\n",
    "We'll connect to Redis running locally in Codespaces. You can also connect to Azure Redis by changing the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e561a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redis configuration\n",
    "USE_LOCAL_REDIS = True  # Set to False for Azure Redis\n",
    "\n",
    "if USE_LOCAL_REDIS:\n",
    "    # Local Redis (in Codespaces)\n",
    "    redis_client = redis.Redis(\n",
    "        host='localhost',\n",
    "        port=6379,\n",
    "        decode_responses=True  # Return strings instead of bytes\n",
    "    )\n",
    "else:\n",
    "    # Azure Redis (update with your values)\n",
    "    redis_client = redis.Redis(\n",
    "        host='your-cache.redis.cache.windows.net',\n",
    "        port=6380,\n",
    "        password='your-access-key',\n",
    "        ssl=True,\n",
    "        decode_responses=True\n",
    "    )\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    redis_client.ping()\n",
    "    print(\"âœ… Connected to Redis successfully!\")\n",
    "    print(f\"   Server info: {redis_client.info('server')['redis_version']}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Redis connection failed: {e}\")\n",
    "    print(\"   Make sure Redis is running: sudo service redis-server start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e62da8",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Create Database Wrapper (5 minutes)\n",
    "\n",
    "Let's create a wrapper class for our PostgreSQL database that tracks query performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79271df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "class PostgreSQLDatabase:\n",
    "    \"\"\"\n",
    "    Wrapper for PostgreSQL database operations.\n",
    "    Tracks query count and provides clean interface for product queries.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"Initialize database connection\"\"\"\n",
    "        if config is None:\n",
    "            config = DB_CONFIG\n",
    "        \n",
    "        self.config = config\n",
    "        self.conn = None\n",
    "        self.query_count = 0\n",
    "        self._connect()\n",
    "    \n",
    "    def _connect(self):\n",
    "        \"\"\"Establish database connection\"\"\"\n",
    "        if self.conn is None or self.conn.closed:\n",
    "            self.conn = psycopg2.connect(**self.config)\n",
    "    \n",
    "    def get_product_by_id(self, product_id: int) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Query product by ID from PostgreSQL.\n",
    "        Returns product data as dictionary or None if not found.\n",
    "        \"\"\"\n",
    "        self._connect()\n",
    "        \n",
    "        with self.conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "            cur.execute(\n",
    "                \"SELECT id, name, price, category, stock FROM products WHERE id = %s\",\n",
    "                (product_id,)\n",
    "            )\n",
    "            result = cur.fetchone()\n",
    "            \n",
    "            self.query_count += 1\n",
    "            \n",
    "            # Convert RealDictRow to regular dict if found\n",
    "            return dict(result) if result else None\n",
    "    \n",
    "    def get_products_by_category(self, category: str) -> List[Dict]:\n",
    "        \"\"\"Query all products in a category\"\"\"\n",
    "        self._connect()\n",
    "        \n",
    "        with self.conn.cursor(cursor_factory=RealDictCursor) as cur:\n",
    "            cur.execute(\n",
    "                \"SELECT id, name, price, category, stock FROM products WHERE category = %s\",\n",
    "                (category,)\n",
    "            )\n",
    "            results = cur.fetchall()\n",
    "            \n",
    "            self.query_count += 1\n",
    "            \n",
    "            return [dict(row) for row in results]\n",
    "    \n",
    "    def reset_stats(self):\n",
    "        \"\"\"Reset query counter\"\"\"\n",
    "        self.query_count = 0\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close database connection\"\"\"\n",
    "        if self.conn and not self.conn.closed:\n",
    "            self.conn.close()\n",
    "\n",
    "# Create database instance\n",
    "db = PostgreSQLDatabase()\n",
    "print(f\"âœ… PostgreSQL database wrapper created\")\n",
    "print(f\"   Connection: {DB_CONFIG['host']}:{DB_CONFIG['port']}\")\n",
    "print(f\"   Database: {DB_CONFIG['database']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6517f4",
   "metadata": {},
   "source": [
    "### ðŸ§ª Test the PostgreSQL Database\n",
    "\n",
    "Let's verify our database wrapper works and measure real query latency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b048020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test database query with timing\n",
    "start_time = time.time()\n",
    "product = db.get_product_by_id(1)\n",
    "elapsed_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "print(f\"Product: {product['name']}\")\n",
    "print(f\"Price: ${product['price']}\")\n",
    "print(f\"Category: {product['category']}\")\n",
    "print(f\"Stock: {product['stock']} units\")\n",
    "print(f\"\\nâ±ï¸  Query time: {elapsed_ms:.2f}ms\")\n",
    "print(f\"ðŸ“Š Total queries: {db.query_count}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Real database query latency will vary based on:\")\n",
    "print(\"   - Network latency\")\n",
    "print(\"   - Database load\")\n",
    "print(\"   - Query complexity\")\n",
    "print(\"   - Index usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb0d90",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Implement Cache-Aside Pattern (15 minutes)\n",
    "\n",
    "Now let's implement the **cache-aside pattern** (also called \"lazy loading\"):\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   App   â”‚\n",
    "â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜\n",
    "     â”‚\n",
    "     â”œâ”€â”€1. Check cache first\n",
    "     â”‚\n",
    "     â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Redis  â”‚ â”€â”€2a. Cache hit? â”€â”€> Return data (fast!)\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "     â”‚\n",
    "     â””â”€â”€2b. Cache miss?\n",
    "         â”‚\n",
    "         â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ Database â”‚ â”€â”€3. Query DB â”€â”€> 4. Store in cache â”€â”€> Return data\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aebc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheManager:\n",
    "    \"\"\"\n",
    "    Implements cache-aside pattern with Redis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, redis_client: redis.Redis, ttl: int = 60):\n",
    "        self.redis = redis_client\n",
    "        self.ttl = ttl  # Time-to-live in seconds\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def get_cached_product(self, product_id: int) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Try to get product from cache.\n",
    "        Returns None if not found (cache miss).\n",
    "        \"\"\"\n",
    "        key = f\"product:{product_id}\"\n",
    "        \n",
    "        try:\n",
    "            cached_data = self.redis.get(key)\n",
    "            \n",
    "            if cached_data:\n",
    "                self.hits += 1\n",
    "                return json.loads(cached_data)\n",
    "            else:\n",
    "                self.misses += 1\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Cache read error: {e}\")\n",
    "            self.misses += 1\n",
    "            return None\n",
    "    \n",
    "    def set_cached_product(self, product_id: int, product_data: Dict):\n",
    "        \"\"\"\n",
    "        Store product in cache with TTL.\n",
    "        \"\"\"\n",
    "        key = f\"product:{product_id}\"\n",
    "        \n",
    "        try:\n",
    "            self.redis.setex(\n",
    "                key,\n",
    "                self.ttl,\n",
    "                json.dumps(product_data)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Cache write error: {e}\")\n",
    "    \n",
    "    def invalidate_product(self, product_id: int):\n",
    "        \"\"\"\n",
    "        Remove product from cache (e.g., after update).\n",
    "        \"\"\"\n",
    "        key = f\"product:{product_id}\"\n",
    "        self.redis.delete(key)\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Return cache performance statistics.\n",
    "        \"\"\"\n",
    "        total = self.hits + self.misses\n",
    "        hit_rate = (self.hits / total * 100) if total > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"hits\": self.hits,\n",
    "            \"misses\": self.misses,\n",
    "            \"total\": total,\n",
    "            \"hit_rate\": hit_rate\n",
    "        }\n",
    "    \n",
    "    def reset_stats(self):\n",
    "        \"\"\"Reset statistics\"\"\"\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "\n",
    "# Create cache manager\n",
    "cache = CacheManager(redis_client, ttl=60)\n",
    "print(\"âœ… Cache manager created with 60-second TTL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49599202",
   "metadata": {},
   "source": [
    "### ðŸ”— Create Helper Function\n",
    "\n",
    "This function implements the complete cache-aside pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce22686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_with_cache(product_id: int, cache_manager: CacheManager, database: PostgreSQLDatabase) -> Dict:\n",
    "    \"\"\"\n",
    "    Get product using cache-aside pattern.\n",
    "    Returns product data with performance metrics.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Check cache first\n",
    "    product = cache_manager.get_cached_product(product_id)\n",
    "    \n",
    "    if product:\n",
    "        # Cache hit!\n",
    "        source = \"cache\"\n",
    "    else:\n",
    "        # Cache miss - get from database\n",
    "        product = database.get_product_by_id(product_id)\n",
    "        \n",
    "        if product:\n",
    "            # Store in cache for next time\n",
    "            cache_manager.set_cached_product(product_id, product)\n",
    "        \n",
    "        source = \"database\"\n",
    "    \n",
    "    elapsed_ms = (time.time() - start_time) * 1000\n",
    "    \n",
    "    return {\n",
    "        \"product\": product,\n",
    "        \"latency_ms\": elapsed_ms,\n",
    "        \"source\": source\n",
    "    }\n",
    "\n",
    "print(\"âœ… Helper function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d92d0",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Performance Testing (15 minutes)\n",
    "\n",
    "Let's measure the real performance improvement from caching!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a640811b",
   "metadata": {},
   "source": [
    "### ðŸ§ª Test 1: Single Product Lookup\n",
    "\n",
    "Compare first request (cache miss) vs. second request (cache hit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6160ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset stats\n",
    "cache.reset_stats()\n",
    "db.reset_stats()\n",
    "redis_client.flushdb()  # Clear cache\n",
    "\n",
    "# First request - cache miss\n",
    "result1 = get_product_with_cache(1, cache, db)\n",
    "print(\"First request (cache miss):\")\n",
    "print(f\"  Product: {result1['product']['name']}\")\n",
    "print(f\"  Latency: {result1['latency_ms']:.2f}ms\")\n",
    "print(f\"  Source: {result1['source']}\")\n",
    "\n",
    "# Second request - cache hit\n",
    "result2 = get_product_with_cache(1, cache, db)\n",
    "print(\"\\nSecond request (cache hit):\")\n",
    "print(f\"  Product: {result2['product']['name']}\")\n",
    "print(f\"  Latency: {result2['latency_ms']:.2f}ms\")\n",
    "print(f\"  Source: {result2['source']}\")\n",
    "\n",
    "# Calculate speedup\n",
    "speedup = result1['latency_ms'] / result2['latency_ms']\n",
    "print(f\"\\nðŸš€ Speedup: {speedup:.1f}x faster with cache!\")\n",
    "print(f\"ðŸ“Š Cache stats: {cache.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb484ae4",
   "metadata": {},
   "source": [
    "### ðŸ“ˆ Test 2: Realistic Traffic Pattern\n",
    "\n",
    "Simulate 100 requests with 80% focused on popular products (realistic e-commerce pattern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset\n",
    "cache.reset_stats()\n",
    "db.reset_stats()\n",
    "redis_client.flushdb()\n",
    "\n",
    "# Simulate traffic\n",
    "results = []\n",
    "num_requests = 100\n",
    "\n",
    "print(f\"Simulating {num_requests} requests...\")\n",
    "\n",
    "for i in range(num_requests):\n",
    "    # 80% of traffic goes to popular products (1-3)\n",
    "    # 20% goes to other products (4-10)\n",
    "    if random.random() < 0.8:\n",
    "        product_id = random.randint(1, 3)\n",
    "    else:\n",
    "        product_id = random.randint(4, 10)\n",
    "    \n",
    "    result = get_product_with_cache(product_id, cache, db)\n",
    "    \n",
    "    results.append({\n",
    "        \"request_num\": i + 1,\n",
    "        \"product_id\": product_id,\n",
    "        \"latency\": result[\"latency_ms\"],\n",
    "        \"source\": result[\"source\"]\n",
    "    })\n",
    "\n",
    "# Show statistics\n",
    "stats = cache.get_stats()\n",
    "print(f\"\\nâœ… Test complete!\")\n",
    "print(f\"\\nðŸ“Š Performance Summary:\")\n",
    "print(f\"  Total Requests: {num_requests}\")\n",
    "print(f\"  Cache Hits: {stats['hits']} ({stats['hit_rate']:.1f}%)\")\n",
    "print(f\"  Cache Misses: {stats['misses']}\")\n",
    "print(f\"  Database Queries: {db.query_count}\")\n",
    "print(f\"\\nðŸ’¡ We avoided {stats['hits']} database queries using cache!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd824e0",
   "metadata": {},
   "source": [
    "### ðŸ”„ Test 3: Cache Invalidation\n",
    "\n",
    "What happens when we update a product? We need to invalidate the cache!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get product (should be cached from previous test)\n",
    "result = get_product_with_cache(1, cache, db)\n",
    "print(\"Before update:\")\n",
    "print(f\"  Product: {result['product']['name']}\")\n",
    "print(f\"  Price: ${result['product']['price']}\")\n",
    "print(f\"  Source: {result['source']}\")\n",
    "\n",
    "# Simulate product update in database using SQL UPDATE\n",
    "with db.conn.cursor() as cur:\n",
    "    cur.execute(\"UPDATE products SET price = %s WHERE id = %s\", (799.99, 1))\n",
    "    db.conn.commit()\n",
    "print(\"\\nâœï¸ Updated price in database to $799.99\")\n",
    "\n",
    "# Get again - still returns OLD cached value!\n",
    "result = get_product_with_cache(1, cache, db)\n",
    "print(\"\\nAfter DB update (cache NOT invalidated):\")\n",
    "print(f\"  Price: ${result['product']['price']} âš ï¸ Still old value!\")\n",
    "print(f\"  Source: {result['source']}\")\n",
    "\n",
    "# Invalidate cache\n",
    "cache.invalidate_product(1)\n",
    "print(\"\\nðŸ—‘ï¸ Cache invalidated for product 1\")\n",
    "\n",
    "# Now get fresh data\n",
    "result = get_product_with_cache(1, cache, db)\n",
    "print(\"\\nAfter cache invalidation:\")\n",
    "print(f\"  Price: ${result['product']['price']} âœ… Now correct!\")\n",
    "print(f\"  Source: {result['source']}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Key lesson: Always invalidate cache when updating data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d29d3",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Visualize Performance (10 minutes)\n",
    "\n",
    "Let's create beautiful charts to visualize the cache effectiveness!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1016507",
   "metadata": {},
   "source": [
    "### ðŸ“Š Chart 1: Request Latency Scatter Plot\n",
    "\n",
    "Show cache hits (green) vs. cache misses (red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e851ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Color by source\n",
    "colors = ['red' if source == 'database' else 'green' for source in df['source']]\n",
    "\n",
    "plt.scatter(df['request_num'], df['latency'], c=colors, alpha=0.6, s=50)\n",
    "plt.xlabel('Request Number', fontsize=12)\n",
    "plt.ylabel('Latency (ms)', fontsize=12)\n",
    "plt.title('Request Latency: Cache Miss (Red) vs Cache Hit (Green)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', alpha=0.6, label='Cache Miss (Database)'),\n",
    "    Patch(facecolor='green', alpha=0.6, label='Cache Hit (Redis)')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Notice how green dots (cache hits) cluster at low latency!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150be353",
   "metadata": {},
   "source": [
    "### ðŸ“Š Chart 2: Average Latency Comparison\n",
    "\n",
    "Bar chart comparing average latency for cache hits vs. misses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages\n",
    "cached = df[df['source'] == 'cache']['latency']\n",
    "uncached = df[df['source'] == 'database']['latency']\n",
    "\n",
    "avg_cached = cached.mean()\n",
    "avg_uncached = uncached.mean()\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bars = plt.bar(\n",
    "    ['Database\\n(Uncached)', 'Redis\\n(Cached)'],\n",
    "    [avg_uncached, avg_cached],\n",
    "    color=['#ff6b6b', '#51cf66'],\n",
    "    width=0.6\n",
    ")\n",
    "\n",
    "plt.ylabel('Average Latency (ms)', fontsize=12)\n",
    "plt.title('Performance Comparison: Database vs Cache', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, [avg_uncached, avg_cached])):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, value + 0.5,\n",
    "             f'{value:.2f}ms',\n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "# Add speedup annotation\n",
    "speedup = avg_uncached / avg_cached\n",
    "plt.text(0.5, max(avg_uncached, avg_cached) * 0.7,\n",
    "         f'{speedup:.1f}x\\nfaster!',\n",
    "         ha='center', fontsize=16, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Performance Summary:\")\n",
    "print(f\"  Average Database Latency: {avg_uncached:.2f}ms\")\n",
    "print(f\"  Average Cache Latency: {avg_cached:.2f}ms\")\n",
    "print(f\"  Speedup: {speedup:.1f}x faster with cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ec02d9",
   "metadata": {},
   "source": [
    "### ðŸ“Š Chart 3: Cache Hit Rate Over Time\n",
    "\n",
    "Line chart showing how hit rate improves as cache warms up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ce1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative hit rate\n",
    "df['is_hit'] = (df['source'] == 'cache').astype(int)\n",
    "df['cumulative_hits'] = df['is_hit'].cumsum()\n",
    "df['hit_rate'] = (df['cumulative_hits'] / df['request_num']) * 100\n",
    "\n",
    "# Create line chart\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(df['request_num'], df['hit_rate'], linewidth=2, color='#4ecdc4')\n",
    "plt.fill_between(df['request_num'], df['hit_rate'], alpha=0.3, color='#4ecdc4')\n",
    "\n",
    "plt.xlabel('Request Number', fontsize=12)\n",
    "plt.ylabel('Cache Hit Rate (%)', fontsize=12)\n",
    "plt.title('Cache Hit Rate Over Time', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "# Add final hit rate annotation\n",
    "final_hit_rate = df['hit_rate'].iloc[-1]\n",
    "plt.axhline(y=final_hit_rate, color='red', linestyle='--', alpha=0.5)\n",
    "plt.text(num_requests * 0.7, final_hit_rate + 5,\n",
    "         f'Final: {final_hit_rate:.1f}%',\n",
    "         fontsize=12, fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ’¡ Hit rate stabilizes around {final_hit_rate:.1f}% after cache warms up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e64b6",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Advanced Exercises (15 minutes)\n",
    "\n",
    "Now it's your turn to experiment! Try these exercises to deepen your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850575ed",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 1: Test TTL Expiration\n",
    "\n",
    "Create a cache with a very short TTL (5 seconds) and observe what happens when the cache expires.\n",
    "\n",
    "**Hints:**\n",
    "- Create a `CacheManager` with `ttl=5`\n",
    "- Make a request (cache miss)\n",
    "- Make another request immediately (cache hit)\n",
    "- Wait 6 seconds using `time.sleep(6)`\n",
    "- Make a third request (cache miss again!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "print(\"Exercise 1: TTL Expiration Test\")\n",
    "print(\"================================\\n\")\n",
    "\n",
    "# TODO: Create cache with TTL=5\n",
    "# TODO: Make requests and observe cache expiration\n",
    "\n",
    "# Solution (uncomment to reveal):\n",
    "# short_cache = CacheManager(redis_client, ttl=5)\n",
    "# redis_client.flushdb()\n",
    "# \n",
    "# result1 = get_product_with_cache(1, short_cache, db)\n",
    "# print(f\"Request 1: {result1['source']} - {result1['latency_ms']:.2f}ms\")\n",
    "# \n",
    "# result2 = get_product_with_cache(1, short_cache, db)\n",
    "# print(f\"Request 2: {result2['source']} - {result2['latency_ms']:.2f}ms\")\n",
    "# \n",
    "# print(\"\\nWaiting 6 seconds for TTL to expire...\")\n",
    "# time.sleep(6)\n",
    "# \n",
    "# result3 = get_product_with_cache(1, short_cache, db)\n",
    "# print(f\"Request 3: {result3['source']} - {result3['latency_ms']:.2f}ms\")\n",
    "# print(\"\\nðŸ’¡ Cache expired! Back to database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523082e8",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 2: Implement Cache Warming\n",
    "\n",
    "Write a function to \"warm up\" the cache by pre-loading popular products before traffic starts.\n",
    "\n",
    "**Hints:**\n",
    "- Create a function `warm_cache(product_ids, cache, db)`\n",
    "- Loop through product IDs\n",
    "- Fetch from database and store in cache\n",
    "- Test with products [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "print(\"Exercise 2: Cache Warming\")\n",
    "print(\"=========================\\n\")\n",
    "\n",
    "def warm_cache(product_ids: List[int], cache_manager: CacheManager, database: PostgreSQLDatabase):\n",
    "    \"\"\"Pre-load products into cache\"\"\"\n",
    "    # TODO: Implement cache warming\n",
    "    pass\n",
    "\n",
    "# TODO: Test your function\n",
    "\n",
    "# Solution (uncomment to reveal):\n",
    "# def warm_cache(product_ids: List[int], cache_manager: CacheManager, database: PostgreSQLDatabase):\n",
    "#     print(f\"Warming cache with {len(product_ids)} products...\")\n",
    "#     for pid in product_ids:\n",
    "#         product = database.get_product_by_id(pid)\n",
    "#         if product:\n",
    "#             cache_manager.set_cached_product(pid, product)\n",
    "#     print(\"âœ… Cache warmed!\")\n",
    "# \n",
    "# redis_client.flushdb()\n",
    "# cache.reset_stats()\n",
    "# warm_cache([1, 2, 3], cache, db)\n",
    "# \n",
    "# # Test - should all be cache hits\n",
    "# for pid in [1, 2, 3]:\n",
    "#     result = get_product_with_cache(pid, cache, db)\n",
    "#     print(f\"Product {pid}: {result['source']} - {result['latency_ms']:.2f}ms\")\n",
    "# \n",
    "# print(f\"\\nStats: {cache.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b4a18",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Exercise 3: Compare Different TTL Values\n",
    "\n",
    "Run the traffic simulation with different TTL values (30s, 60s, 300s) and compare the hit rates.\n",
    "\n",
    "**Questions to explore:**\n",
    "- Does longer TTL always give better hit rates?\n",
    "- What's the trade-off?\n",
    "- When would you use a short TTL vs. long TTL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "print(\"Exercise 3: TTL Comparison\")\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "# TODO: Test with different TTL values and compare results\n",
    "\n",
    "# Starter code:\n",
    "ttl_values = [30, 60, 300]\n",
    "results_by_ttl = {}\n",
    "\n",
    "# for ttl in ttl_values:\n",
    "#     # Create cache with this TTL\n",
    "#     # Run simulation\n",
    "#     # Store results\n",
    "#     pass\n",
    "\n",
    "# TODO: Create comparison chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5667077",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Exercises and Key Takeaways (15 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479cbb3",
   "metadata": {},
   "source": [
    "## ðŸŽ“ What You've Learned\n",
    "\n",
    "Congratulations! You now understand:\n",
    "\n",
    "### âœ… Cache-Aside Pattern\n",
    "- Check cache first, fall back to database\n",
    "- Store in cache on miss\n",
    "- Simple but effective!\n",
    "\n",
    "### âœ… Performance Benefits\n",
    "- **10-100x speedup** with caching\n",
    "- Hit rates of **80-90%** are common\n",
    "- Dramatically reduces database load\n",
    "\n",
    "### âœ… Cache Invalidation\n",
    "- **Must invalidate on updates**\n",
    "- Otherwise, users see stale data\n",
    "- Use TTL as safety net\n",
    "\n",
    "### âœ… TTL Strategy\n",
    "- Shorter TTL = fresher data, more DB queries\n",
    "- Longer TTL = better performance, staler data\n",
    "- Choose based on requirements\n",
    "\n",
    "### âœ… Monitoring\n",
    "- Track hit rate\n",
    "- Measure latency\n",
    "- Visualize effectiveness\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "1. **Try in your own app** - Apply these patterns to your project\n",
    "2. **Explore other patterns** - Write-through, write-behind, refresh-ahead\n",
    "3. **Learn advanced features** - Redis Pub/Sub, Streams, RedisJSON\n",
    "4. **Study monitoring** - Use Azure Monitor and Redis Insights\n",
    "\n",
    "## ðŸ“š Resources\n",
    "\n",
    "- [Redis Caching Best Practices](https://redis.io/docs/manual/patterns/caching/)\n",
    "- [Cache-Aside Pattern](https://learn.microsoft.com/azure/architecture/patterns/cache-aside)\n",
    "- [Redis Python Client](https://redis-py.readthedocs.io/)\n",
    "- [Azure Cache for Redis](https://learn.microsoft.com/azure/azure-cache-for-redis/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ecafd",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Cleanup\n",
    "\n",
    "Run this cell to clean up Redis and reset everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ba4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all Redis keys\n",
    "redis_client.flushdb()\n",
    "\n",
    "# Reset stats\n",
    "cache.reset_stats()\n",
    "db.reset_stats()\n",
    "\n",
    "print(\"âœ… Cleanup complete!\")\n",
    "print(\"\\nðŸŽ‰ Thank you for completing the Caching Lab!\")\n",
    "print(\"   You're now ready to implement Redis caching in production!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d211e",
   "metadata": {},
   "source": [
    "# Module 6: Implement Caching Lab\n",
    "\n",
    "**Duration:** 60 minutes  \n",
    "**Format:** Interactive Hands-On Lab  \n",
    "**Level:** Intermediate\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Lab Overview\n",
    "\n",
    "In this interactive notebook, you'll:\n",
    "- Build a Flask REST API with PostgreSQL backend\n",
    "- Implement cache-aside pattern with Redis\n",
    "- Measure cache performance improvements\n",
    "- Test cache invalidation strategies\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "Client â†’ Flask API â†’ Redis Cache (check first)\n",
    "                   â†’ PostgreSQL (on cache miss)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62818889",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Part 1: Setup and Dependencies\n",
    "\n",
    "Let's start by importing required libraries and setting up connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439a5592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import redis\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e218b91",
   "metadata": {},
   "source": [
    "### Configure Redis Connection\n",
    "\n",
    "Set up your Azure Redis connection. Update these values with your Redis instance details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5605297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redis Configuration\n",
    "# Option 1: Use local Redis (Codespaces)\n",
    "USE_LOCAL_REDIS = True\n",
    "\n",
    "if USE_LOCAL_REDIS:\n",
    "    REDIS_HOST = 'localhost'\n",
    "    REDIS_PORT = 6379\n",
    "    REDIS_PASSWORD = None\n",
    "    REDIS_SSL = False\n",
    "else:\n",
    "    # Option 2: Use Azure Redis (replace with your values)\n",
    "    REDIS_HOST = os.getenv('REDIS_HOST', 'your-redis.redis.cache.windows.net')\n",
    "    REDIS_PORT = int(os.getenv('REDIS_PORT', 6380))\n",
    "    REDIS_PASSWORD = os.getenv('REDIS_PASSWORD', 'your-access-key')\n",
    "    REDIS_SSL = True\n",
    "\n",
    "# Cache TTL (seconds)\n",
    "CACHE_TTL = 60\n",
    "\n",
    "print(f\"ðŸ”§ Redis Configuration:\")\n",
    "print(f\"   Host: {REDIS_HOST}\")\n",
    "print(f\"   Port: {REDIS_PORT}\")\n",
    "print(f\"   SSL: {REDIS_SSL}\")\n",
    "print(f\"   TTL: {CACHE_TTL}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a19036",
   "metadata": {},
   "source": [
    "### Initialize Redis Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fa10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Redis\n",
    "try:\n",
    "    redis_client = redis.Redis(\n",
    "        host=REDIS_HOST,\n",
    "        port=REDIS_PORT,\n",
    "        password=REDIS_PASSWORD,\n",
    "        ssl=REDIS_SSL,\n",
    "        decode_responses=True\n",
    "    )\n",
    "    \n",
    "    # Test connection\n",
    "    redis_client.ping()\n",
    "    print(\"âœ… Connected to Redis successfully!\")\n",
    "    \n",
    "    # Get Redis info\n",
    "    info = redis_client.info('server')\n",
    "    print(f\"   Version: {info['redis_version']}\")\n",
    "    print(f\"   Memory: {info.get('used_memory_human', 'N/A')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to connect to Redis: {e}\")\n",
    "    redis_client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8b993",
   "metadata": {},
   "source": [
    "### Setup PostgreSQL Database\n",
    "\n",
    "For this lab, we'll use an in-memory database simulation to avoid Docker requirements in Codespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce15bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Database (in-memory)\n",
    "# In production, you'd connect to PostgreSQL\n",
    "\n",
    "class MockDatabase:\n",
    "    \"\"\"Simulated database for the lab\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.products = [\n",
    "            {'id': 1, 'sku': 'LAPTOP-001', 'name': 'MacBook Pro 16\"', 'price': 2499.99, 'stock': 15, 'category': 'Electronics'},\n",
    "            {'id': 2, 'sku': 'LAPTOP-002', 'name': 'Dell XPS 15', 'price': 1799.99, 'stock': 25, 'category': 'Electronics'},\n",
    "            {'id': 3, 'sku': 'PHONE-001', 'name': 'iPhone 15 Pro', 'price': 999.99, 'stock': 50, 'category': 'Electronics'},\n",
    "            {'id': 4, 'sku': 'PHONE-002', 'name': 'Samsung Galaxy S24', 'price': 899.99, 'stock': 40, 'category': 'Electronics'},\n",
    "            {'id': 5, 'sku': 'TABLET-001', 'name': 'iPad Pro 12.9\"', 'price': 1099.99, 'stock': 20, 'category': 'Electronics'},\n",
    "            {'id': 6, 'sku': 'MONITOR-001', 'name': 'LG 27\" 4K', 'price': 499.99, 'stock': 30, 'category': 'Electronics'},\n",
    "            {'id': 7, 'sku': 'KEYBOARD-001', 'name': 'Mechanical Keyboard', 'price': 149.99, 'stock': 100, 'category': 'Accessories'},\n",
    "            {'id': 8, 'sku': 'MOUSE-001', 'name': 'Wireless Mouse', 'price': 79.99, 'stock': 150, 'category': 'Accessories'},\n",
    "            {'id': 9, 'sku': 'HEADSET-001', 'name': 'Noise-Cancelling Headset', 'price': 299.99, 'stock': 60, 'category': 'Accessories'},\n",
    "            {'id': 10, 'sku': 'WEBCAM-001', 'name': '1080p Webcam', 'price': 89.99, 'stock': 75, 'category': 'Accessories'},\n",
    "        ]\n",
    "        self.query_count = 0\n",
    "    \n",
    "    def get_all_products(self):\n",
    "        \"\"\"Simulate slow database query\"\"\"\n",
    "        time.sleep(0.03)  # Simulate 30ms query time\n",
    "        self.query_count += 1\n",
    "        return self.products.copy()\n",
    "    \n",
    "    def get_product_by_id(self, product_id):\n",
    "        \"\"\"Simulate database lookup\"\"\"\n",
    "        time.sleep(0.025)  # Simulate 25ms query time\n",
    "        self.query_count += 1\n",
    "        for product in self.products:\n",
    "            if product['id'] == product_id:\n",
    "                return product.copy()\n",
    "        return None\n",
    "    \n",
    "    def update_product(self, product_id, updates):\n",
    "        \"\"\"Update product in database\"\"\"\n",
    "        time.sleep(0.02)  # Simulate 20ms write time\n",
    "        self.query_count += 1\n",
    "        for product in self.products:\n",
    "            if product['id'] == product_id:\n",
    "                product.update(updates)\n",
    "                return product.copy()\n",
    "        return None\n",
    "\n",
    "# Initialize database\n",
    "db = MockDatabase()\n",
    "print(f\"âœ… Database initialized with {len(db.products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863aa2b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”„ Part 2: Implement Cache-Aside Pattern\n",
    "\n",
    "Now let's implement the cache-aside pattern:\n",
    "1. Check cache first\n",
    "2. If miss, query database\n",
    "3. Store result in cache\n",
    "4. Return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bcc370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache Manager Class\n",
    "\n",
    "class CacheManager:\n",
    "    \"\"\"Manages cache operations with Redis\"\"\"\n",
    "    \n",
    "    def __init__(self, redis_client, ttl=60):\n",
    "        self.redis = redis_client\n",
    "        self.ttl = ttl\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def get_product_key(self, product_id):\n",
    "        return f\"product:{product_id}\"\n",
    "    \n",
    "    def get_products_list_key(self):\n",
    "        return \"products:all\"\n",
    "    \n",
    "    def get_cached_product(self, product_id):\n",
    "        \"\"\"Try to get product from cache\"\"\"\n",
    "        key = self.get_product_key(product_id)\n",
    "        cached = self.redis.get(key)\n",
    "        \n",
    "        if cached:\n",
    "            self.hits += 1\n",
    "            return json.loads(cached)\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            return None\n",
    "    \n",
    "    def set_cached_product(self, product_id, product_data):\n",
    "        \"\"\"Store product in cache\"\"\"\n",
    "        key = self.get_product_key(product_id)\n",
    "        self.redis.setex(key, self.ttl, json.dumps(product_data))\n",
    "    \n",
    "    def get_cached_products_list(self):\n",
    "        \"\"\"Try to get products list from cache\"\"\"\n",
    "        key = self.get_products_list_key()\n",
    "        cached = self.redis.get(key)\n",
    "        \n",
    "        if cached:\n",
    "            self.hits += 1\n",
    "            return json.loads(cached)\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            return None\n",
    "    \n",
    "    def set_cached_products_list(self, products):\n",
    "        \"\"\"Store products list in cache\"\"\"\n",
    "        key = self.get_products_list_key()\n",
    "        self.redis.setex(key, self.ttl, json.dumps(products))\n",
    "    \n",
    "    def invalidate_product(self, product_id):\n",
    "        \"\"\"Remove product from cache\"\"\"\n",
    "        key = self.get_product_key(product_id)\n",
    "        self.redis.delete(key)\n",
    "        # Also invalidate products list\n",
    "        self.redis.delete(self.get_products_list_key())\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get cache statistics\"\"\"\n",
    "        total = self.hits + self.misses\n",
    "        hit_rate = (self.hits / total * 100) if total > 0 else 0\n",
    "        return {\n",
    "            'hits': self.hits,\n",
    "            'misses': self.misses,\n",
    "            'total': total,\n",
    "            'hit_rate': round(hit_rate, 2)\n",
    "        }\n",
    "    \n",
    "    def reset_stats(self):\n",
    "        \"\"\"Reset statistics\"\"\"\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "\n",
    "# Initialize cache manager\n",
    "cache = CacheManager(redis_client, ttl=CACHE_TTL)\n",
    "print(\"âœ… Cache Manager initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7aa1d1",
   "metadata": {},
   "source": [
    "### Create API Functions with Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37096416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_with_cache():\n",
    "    \"\"\"Get all products (with caching)\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Try cache first\n",
    "    products = cache.get_cached_products_list()\n",
    "    \n",
    "    if products:\n",
    "        latency = (time.time() - start_time) * 1000\n",
    "        return {\n",
    "            'data': products,\n",
    "            'cached': True,\n",
    "            'latency_ms': round(latency, 2)\n",
    "        }\n",
    "    \n",
    "    # Cache miss - fetch from database\n",
    "    products = db.get_all_products()\n",
    "    \n",
    "    # Store in cache for next time\n",
    "    cache.set_cached_products_list(products)\n",
    "    \n",
    "    latency = (time.time() - start_time) * 1000\n",
    "    \n",
    "    return {\n",
    "        'data': products,\n",
    "        'cached': False,\n",
    "        'latency_ms': round(latency, 2)\n",
    "    }\n",
    "\n",
    "def get_product_with_cache(product_id):\n",
    "    \"\"\"Get single product by ID (with caching)\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Try cache first\n",
    "    product = cache.get_cached_product(product_id)\n",
    "    \n",
    "    if product:\n",
    "        latency = (time.time() - start_time) * 1000\n",
    "        return {\n",
    "            'data': product,\n",
    "            'cached': True,\n",
    "            'latency_ms': round(latency, 2)\n",
    "        }\n",
    "    \n",
    "    # Cache miss - fetch from database\n",
    "    product = db.get_product_by_id(product_id)\n",
    "    \n",
    "    if not product:\n",
    "        return {'error': 'Product not found'}\n",
    "    \n",
    "    # Store in cache for next time\n",
    "    cache.set_cached_product(product_id, product)\n",
    "    \n",
    "    latency = (time.time() - start_time) * 1000\n",
    "    \n",
    "    return {\n",
    "        'data': product,\n",
    "        'cached': False,\n",
    "        'latency_ms': round(latency, 2)\n",
    "    }\n",
    "\n",
    "def update_product_with_cache(product_id, updates):\n",
    "    \"\"\"Update product (with cache invalidation)\"\"\"\n",
    "    # Update database\n",
    "    product = db.update_product(product_id, updates)\n",
    "    \n",
    "    if not product:\n",
    "        return {'error': 'Product not found'}\n",
    "    \n",
    "    # Invalidate cache\n",
    "    cache.invalidate_product(product_id)\n",
    "    \n",
    "    return {\n",
    "        'data': product,\n",
    "        'message': 'Product updated and cache invalidated'\n",
    "    }\n",
    "\n",
    "print(\"âœ… API functions created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a6230",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ§ª Part 3: Test Cache Performance\n",
    "\n",
    "Let's test the cache and measure performance improvements!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17dbcab",
   "metadata": {},
   "source": [
    "### Test 1: Single Product Lookup (Cache Miss â†’ Hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282950cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset stats\n",
    "cache.reset_stats()\n",
    "redis_client.flushdb()  # Clear all cache\n",
    "\n",
    "print(\"ðŸ” Test 1: Single Product Lookup\\n\")\n",
    "\n",
    "# First request (cache miss)\n",
    "print(\"First request (cache miss):\")\n",
    "result1 = get_product_with_cache(1)\n",
    "print(f\"  Product: {result1['data']['name']}\")\n",
    "print(f\"  Cached: {result1['cached']}\")\n",
    "print(f\"  Latency: {result1['latency_ms']}ms\")\n",
    "print()\n",
    "\n",
    "# Second request (cache hit)\n",
    "print(\"Second request (cache hit):\")\n",
    "result2 = get_product_with_cache(1)\n",
    "print(f\"  Product: {result2['data']['name']}\")\n",
    "print(f\"  Cached: {result2['cached']}\")\n",
    "print(f\"  Latency: {result2['latency_ms']}ms\")\n",
    "print()\n",
    "\n",
    "# Performance improvement\n",
    "improvement = ((result1['latency_ms'] - result2['latency_ms']) / result1['latency_ms']) * 100\n",
    "print(f\"âš¡ Performance Improvement: {improvement:.1f}%\")\n",
    "print(f\"âš¡ Speedup: {result1['latency_ms'] / result2['latency_ms']:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4bdf9",
   "metadata": {},
   "source": [
    "### Test 2: Multiple Requests (Measure Hit Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset stats\n",
    "cache.reset_stats()\n",
    "redis_client.flushdb()\n",
    "\n",
    "print(\"ðŸ”„ Test 2: Multiple Requests\\n\")\n",
    "\n",
    "# Simulate 100 requests with 80% being for the same products\n",
    "import random\n",
    "\n",
    "latencies = []\n",
    "product_ids = [1, 2, 3, 4, 5]  # Focus on first 5 products\n",
    "\n",
    "for i in range(100):\n",
    "    # 80% chance of requesting popular products\n",
    "    if random.random() < 0.8:\n",
    "        product_id = random.choice(product_ids[:3])  # Top 3 products\n",
    "    else:\n",
    "        product_id = random.choice(product_ids)\n",
    "    \n",
    "    result = get_product_with_cache(product_id)\n",
    "    latencies.append(result['latency_ms'])\n",
    "\n",
    "# Get cache statistics\n",
    "stats = cache.get_stats()\n",
    "\n",
    "print(f\"ðŸ“Š Results after 100 requests:\")\n",
    "print(f\"  Cache Hits: {stats['hits']}\")\n",
    "print(f\"  Cache Misses: {stats['misses']}\")\n",
    "print(f\"  Hit Rate: {stats['hit_rate']}%\")\n",
    "print(f\"  Avg Latency: {sum(latencies)/len(latencies):.2f}ms\")\n",
    "print(f\"  Min Latency: {min(latencies):.2f}ms\")\n",
    "print(f\"  Max Latency: {max(latencies):.2f}ms\")\n",
    "print(f\"  DB Queries: {db.query_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9da0006",
   "metadata": {},
   "source": [
    "### Test 3: Cache Invalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97495b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”„ Test 3: Cache Invalidation\\n\")\n",
    "\n",
    "# Get product (cache it)\n",
    "print(\"1. Get product (will be cached):\")\n",
    "result = get_product_with_cache(1)\n",
    "print(f\"   Price: ${result['data']['price']}\")\n",
    "print(f\"   Cached: {result['cached']}\")\n",
    "print()\n",
    "\n",
    "# Verify it's cached\n",
    "print(\"2. Get same product again (should be cached):\")\n",
    "result = get_product_with_cache(1)\n",
    "print(f\"   Price: ${result['data']['price']}\")\n",
    "print(f\"   Cached: {result['cached']}\")\n",
    "print()\n",
    "\n",
    "# Update product (invalidates cache)\n",
    "print(\"3. Update product price (invalidates cache):\")\n",
    "result = update_product_with_cache(1, {'price': 2599.99})\n",
    "print(f\"   New Price: ${result['data']['price']}\")\n",
    "print(f\"   Message: {result['message']}\")\n",
    "print()\n",
    "\n",
    "# Get product again (cache miss)\n",
    "print(\"4. Get product again (cache was invalidated):\")\n",
    "result = get_product_with_cache(1)\n",
    "print(f\"   Price: ${result['data']['price']}\")\n",
    "print(f\"   Cached: {result['cached']} (Expected: False)\")\n",
    "print()\n",
    "\n",
    "print(\"âœ… Cache invalidation working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad7679",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š Part 4: Performance Visualization\n",
    "\n",
    "Let's visualize the performance difference between cached and uncached requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison test\n",
    "\n",
    "def benchmark_cache_performance(num_requests=50):\n",
    "    \"\"\"Benchmark cached vs uncached performance\"\"\"\n",
    "    \n",
    "    results = {\n",
    "        'request_num': [],\n",
    "        'latency': [],\n",
    "        'cached': [],\n",
    "        'type': []\n",
    "    }\n",
    "    \n",
    "    # Clear cache\n",
    "    redis_client.flushdb()\n",
    "    cache.reset_stats()\n",
    "    \n",
    "    # Make requests (mix of first-time and repeated)\n",
    "    for i in range(num_requests):\n",
    "        # Alternate between 3 popular products\n",
    "        product_id = (i % 3) + 1\n",
    "        \n",
    "        result = get_product_with_cache(product_id)\n",
    "        \n",
    "        results['request_num'].append(i + 1)\n",
    "        results['latency'].append(result['latency_ms'])\n",
    "        results['cached'].append('Hit' if result['cached'] else 'Miss')\n",
    "        results['type'].append('Cached' if result['cached'] else 'Database')\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run benchmark\n",
    "print(\"Running performance benchmark...\")\n",
    "df = benchmark_cache_performance(50)\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Latency over time\n",
    "colors = ['red' if x == 'Miss' else 'green' for x in df['cached']]\n",
    "ax1.scatter(df['request_num'], df['latency'], c=colors, alpha=0.6)\n",
    "ax1.set_xlabel('Request Number')\n",
    "ax1.set_ylabel('Latency (ms)')\n",
    "ax1.set_title('Request Latency: Cache Miss (Red) vs Hit (Green)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Average latency comparison\n",
    "avg_cached = df[df['type'] == 'Cached']['latency'].mean()\n",
    "avg_uncached = df[df['type'] == 'Database']['latency'].mean()\n",
    "\n",
    "ax2.bar(['Database\\n(Uncached)', 'Redis\\n(Cached)'], [avg_uncached, avg_cached], \n",
    "        color=['#e74c3c', '#27ae60'])\n",
    "ax2.set_ylabel('Average Latency (ms)')\n",
    "ax2.set_title('Average Response Time Comparison')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add values on bars\n",
    "ax2.text(0, avg_uncached + 1, f'{avg_uncached:.2f}ms', ha='center', va='bottom', fontweight='bold')\n",
    "ax2.text(1, avg_cached + 0.5, f'{avg_cached:.2f}ms', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nðŸ“Š Performance Summary:\")\n",
    "print(f\"  Average Database Latency: {avg_uncached:.2f}ms\")\n",
    "print(f\"  Average Cache Latency: {avg_cached:.2f}ms\")\n",
    "print(f\"  Speedup: {avg_uncached/avg_cached:.1f}x faster with cache\")\n",
    "print(f\"  Cache Hit Rate: {cache.get_stats()['hit_rate']}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c64ff",
   "metadata": {},
   "source": [
    "### Cache Hit Rate Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d81fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative hit rate\n",
    "df['cumulative_hits'] = (df['cached'] == 'Hit').cumsum()\n",
    "df['cumulative_total'] = range(1, len(df) + 1)\n",
    "df['hit_rate'] = (df['cumulative_hits'] / df['cumulative_total']) * 100\n",
    "\n",
    "# Plot hit rate over time\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(df['request_num'], df['hit_rate'], linewidth=2, color='#3498db')\n",
    "plt.fill_between(df['request_num'], df['hit_rate'], alpha=0.3, color='#3498db')\n",
    "plt.xlabel('Request Number')\n",
    "plt.ylabel('Cache Hit Rate (%)')\n",
    "plt.title('Cache Hit Rate Over Time')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 100)\n",
    "plt.axhline(y=80, color='green', linestyle='--', alpha=0.5, label='Target (80%)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Hit Rate: {df['hit_rate'].iloc[-1]:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a2437",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ“ Part 5: Advanced Exercises\n",
    "\n",
    "Try these exercises to deepen your understanding:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd984966",
   "metadata": {},
   "source": [
    "### Exercise 1: Implement TTL Testing\n",
    "\n",
    "Test what happens when cache entries expire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement TTL testing\n",
    "\n",
    "# Hints:\n",
    "# 1. Set a short TTL (e.g., 5 seconds)\n",
    "# 2. Get a product (cache it)\n",
    "# 3. Wait for TTL to expire\n",
    "# 4. Get the same product again\n",
    "# 5. Observe cache miss\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b29da",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement Cache Warming\n",
    "\n",
    "Pre-populate the cache with frequently accessed products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c137442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement cache warming\n",
    "\n",
    "def warm_cache(product_ids):\n",
    "    \"\"\"\n",
    "    Pre-load products into cache\n",
    "    \n",
    "    Args:\n",
    "        product_ids: List of product IDs to warm\n",
    "    \"\"\"\n",
    "    # Your code here:\n",
    "    pass\n",
    "\n",
    "# Test your implementation:\n",
    "# warm_cache([1, 2, 3, 4, 5])\n",
    "# Verify cache contains the products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82478bc",
   "metadata": {},
   "source": [
    "### Exercise 3: Compare Different TTL Values\n",
    "\n",
    "Test how different TTL values affect hit rate and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990e495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test different TTL values\n",
    "\n",
    "# Hints:\n",
    "# 1. Test TTLs: 10s, 60s, 300s, 3600s\n",
    "# 2. Run same benchmark for each\n",
    "# 3. Compare hit rates\n",
    "# 4. Consider trade-offs\n",
    "\n",
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a140b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ Part 6: Key Takeaways\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "âœ… **Cache-Aside Pattern**\n",
    "- Check cache first, then database\n",
    "- Store results for future requests\n",
    "- 10-100x performance improvement\n",
    "\n",
    "âœ… **Cache Invalidation**\n",
    "- Delete cache entries on updates\n",
    "- Prevents stale data\n",
    "- Critical for data consistency\n",
    "\n",
    "âœ… **Performance Metrics**\n",
    "- Cache hit rate (target: 80%+)\n",
    "- Latency reduction (2-5ms vs 20-50ms)\n",
    "- Database load reduction (85%+)\n",
    "\n",
    "âœ… **TTL Strategy**\n",
    "- Balance freshness vs performance\n",
    "- Different TTLs for different data\n",
    "- Consider access patterns\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "1. **Always measure** - Use metrics to validate improvements\n",
    "2. **Cache hot data** - Focus on frequently accessed items\n",
    "3. **Invalidate on writes** - Keep cache consistent\n",
    "4. **Set appropriate TTLs** - Balance freshness and performance\n",
    "5. **Monitor hit rates** - Aim for 80%+ in production\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've successfully implemented Redis caching and measured real performance improvements!\n",
    "\n",
    "**Next Steps:**\n",
    "- Explore Module 7: Monitoring & Alerts\n",
    "- Try the advanced exercises above\n",
    "- Apply caching to your own applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a1f15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ§¹ Cleanup\n",
    "\n",
    "Run this cell to clean up the Redis cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32780865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "try:\n",
    "    redis_client.flushdb()\n",
    "    print(\"âœ… Cache cleared successfully\")\n",
    "    print(f\"ðŸ“Š Final Stats: {cache.get_stats()}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Cleanup failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02370f9",
   "metadata": {},
   "source": [
    "### ðŸ³ Stop Docker Containers\n",
    "\n",
    "When you're done with the lab, stop and remove the Docker containers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a121e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Stop and remove Docker containers\n",
    "echo \"ðŸ›‘ Stopping Docker containers...\"\n",
    "docker stop workshop-postgres workshop-redis 2>/dev/null || true\n",
    "docker rm workshop-postgres workshop-redis 2>/dev/null || true\n",
    "\n",
    "echo \"âœ… Docker containers stopped and removed\"\n",
    "echo \"\"\n",
    "echo \"To verify, run: docker ps -a | grep workshop\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
