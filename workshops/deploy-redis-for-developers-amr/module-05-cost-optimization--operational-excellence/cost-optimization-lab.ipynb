{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Cost Optimization & Operational Excellence\n",
    "\n",
    "## üéØ Interactive Lab: Optimizing Redis Costs\n",
    "\n",
    "**Duration:** 45 minutes  \n",
    "**Level:** Intermediate  \n",
    "\n",
    "In this lab, you'll:\n",
    "- üí∞ Understand Azure Redis pricing models\n",
    "- üìä Monitor memory usage and efficiency\n",
    "- üîç Identify cost optimization opportunities\n",
    "- ‚ö° Implement memory-efficient patterns\n",
    "- üìà Calculate cost savings\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f54c341",
   "metadata": {},
   "source": [
    "## üê≥ Start Docker Redis Container\n",
    "\n",
    "Before we begin, let's start a Redis container using Docker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f74db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Redis container\n",
    "!docker run -d \\\n",
    "  --name workshop-redis-module5 \\\n",
    "  -p 6379:6379 \\\n",
    "  redis:7-alpine\n",
    "\n",
    "# Wait for Redis to be ready\n",
    "import time\n",
    "time.sleep(2)\n",
    "\n",
    "# Test connection\n",
    "!docker exec workshop-redis-module5 redis-cli ping\n",
    "\n",
    "print('‚úÖ Redis container is running on localhost:6379')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q redis\n",
    "\n",
    "import redis\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Connect to Redis\n",
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    r.ping()\n",
    "    print('‚úÖ Connected to Redis')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Connection failed: {e}')\n",
    "    print('   Make sure Redis is running')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Azure Redis Pricing Overview\n",
    "\n",
    "### Pricing Tiers (Monthly Estimates)\n",
    "\n",
    "| Tier | Size | Memory | Est. Cost/Month |\n",
    "|------|------|--------|----------------|\n",
    "| **Basic C1** | 1 GB | 1 GB | ~$18 |\n",
    "| **Basic C2** | 2.5 GB | 2.5 GB | ~$37 |\n",
    "| **Standard C1** | 1 GB | 1 GB | ~$55 |\n",
    "| **Standard C2** | 2.5 GB | 2.5 GB | ~$110 |\n",
    "| **Premium P1** | 6 GB | 6 GB | ~$237 |\n",
    "| **Premium P2** | 13 GB | 13 GB | ~$503 |\n",
    "\n",
    "### Cost Factors\n",
    "\n",
    "1. **Tier Selection** - Basic vs Standard vs Premium\n",
    "2. **Size** - Memory capacity\n",
    "3. **Replication** - Additional replicas\n",
    "4. **Persistence** - RDB/AOF snapshots\n",
    "5. **Data Transfer** - Egress costs\n",
    "\n",
    "### üí° Cost Optimization Strategies\n",
    "\n",
    "1. **Right-size your instance**\n",
    "2. **Use appropriate data structures**\n",
    "3. **Set TTLs on keys**\n",
    "4. **Monitor memory usage**\n",
    "5. **Use compression when beneficial**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Memory Usage Analysis\n",
    "\n",
    "Let's analyze memory usage patterns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_stats():\n",
    "    \"\"\"Get current memory statistics\"\"\"\n",
    "    info = r.info('memory')\n",
    "    \n",
    "    used_mb = info['used_memory'] / 1024 / 1024\n",
    "    peak_mb = info['used_memory_peak'] / 1024 / 1024\n",
    "    rss_mb = info['used_memory_rss'] / 1024 / 1024\n",
    "    \n",
    "    return {\n",
    "        'used_memory_mb': round(used_mb, 2),\n",
    "        'peak_memory_mb': round(peak_mb, 2),\n",
    "        'rss_memory_mb': round(rss_mb, 2),\n",
    "        'fragmentation_ratio': info.get('mem_fragmentation_ratio', 1.0)\n",
    "    }\n",
    "\n",
    "# Get initial stats\n",
    "stats = get_memory_stats()\n",
    "print('üìä Current Memory Usage:')\n",
    "print(f'   Used: {stats[\"used_memory_mb\"]} MB')\n",
    "print(f'   Peak: {stats[\"peak_memory_mb\"]} MB')\n",
    "print(f'   RSS: {stats[\"rss_memory_mb\"]} MB')\n",
    "print(f'   Fragmentation: {stats[\"fragmentation_ratio\"]:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Data Structure Efficiency\n",
    "\n",
    "Different data structures have different memory footprints:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def compare_data_structure_memory():\n",
    "    \"\"\"Compare memory usage of different approaches\"\"\"\n",
    "    \n",
    "    # Clear existing data\n",
    "    r.flushdb()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Approach 1: Individual string keys\n",
    "    initial_mem = get_memory_stats()['used_memory_mb']\n",
    "    \n",
    "    for i in range(1000):\n",
    "        r.set(f'user:{i}:name', f'User{i}')\n",
    "        r.set(f'user:{i}:email', f'user{i}@example.com')\n",
    "        r.set(f'user:{i}:age', 25 + (i % 50))\n",
    "    \n",
    "    string_mem = get_memory_stats()['used_memory_mb'] - initial_mem\n",
    "    results.append(('Individual Strings (3000 keys)', string_mem))\n",
    "    \n",
    "    # Clean up\n",
    "    r.flushdb()\n",
    "    \n",
    "    # Approach 2: Hashes\n",
    "    initial_mem = get_memory_stats()['used_memory_mb']\n",
    "    \n",
    "    for i in range(1000):\n",
    "        r.hset(f'user:{i}', mapping={\n",
    "            'name': f'User{i}',\n",
    "            'email': f'user{i}@example.com',\n",
    "            'age': 25 + (i % 50)\n",
    "        })\n",
    "    \n",
    "    hash_mem = get_memory_stats()['used_memory_mb'] - initial_mem\n",
    "    results.append(('Hashes (1000 keys)', hash_mem))\n",
    "    \n",
    "    # Display results\n",
    "    print('üîç Memory Usage Comparison (1000 users, 3 fields each):')\n",
    "    print()\n",
    "    print(f'{\"Approach\":<30} | {\"Memory (MB)\":<12} | {\"Savings\"}')\n",
    "    print('-' * 60)\n",
    "    \n",
    "    baseline = results[0][1]\n",
    "    for approach, mem in results:\n",
    "        savings = ((baseline - mem) / baseline * 100) if mem < baseline else 0\n",
    "        print(f'{approach:<30} | {mem:>11.2f} | {savings:>5.1f}%')\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run comparison\n",
    "comparison = compare_data_structure_memory()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: TTL Management for Cost Control\n",
    "\n",
    "Setting Time-To-Live (TTL) prevents memory bloat:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_ttl_impact():\n",
    "    \"\"\"Show impact of TTL on memory management\"\"\"\n",
    "    \n",
    "    # Clear database\n",
    "    r.flushdb()\n",
    "    \n",
    "    print('üìä Creating cache entries...')\n",
    "    \n",
    "    # Scenario 1: No TTL (memory grows forever)\n",
    "    print('\\n‚ùå Without TTL:')\n",
    "    for i in range(100):\n",
    "        r.set(f'cache:no_ttl:{i}', f'data_{i}' * 100)\n",
    "    \n",
    "    no_ttl_keys = len(r.keys('cache:no_ttl:*'))\n",
    "    print(f'   Keys: {no_ttl_keys}')\n",
    "    print(f'   Will stay in memory indefinitely')\n",
    "    \n",
    "    # Scenario 2: With TTL (automatic cleanup)\n",
    "    print('\\n‚úÖ With 60s TTL:')\n",
    "    for i in range(100):\n",
    "        r.setex(f'cache:with_ttl:{i}', 60, f'data_{i}' * 100)\n",
    "    \n",
    "    with_ttl_keys = len(r.keys('cache:with_ttl:*'))\n",
    "    print(f'   Keys: {with_ttl_keys}')\n",
    "    print(f'   Will auto-expire in 60 seconds')\n",
    "    \n",
    "    # Show memory stats\n",
    "    stats = get_memory_stats()\n",
    "    print(f'\\nüíæ Current memory usage: {stats[\"used_memory_mb\"]} MB')\n",
    "    \n",
    "    # Calculate monthly cost impact\n",
    "    print('\\nÔøΩÔøΩ Cost Impact (Example):')\n",
    "    print('   Without TTL: Memory keeps growing ‚Üí Requires larger instance')\n",
    "    print('   With TTL: Memory auto-managed ‚Üí Can use smaller instance')\n",
    "    print('   Potential savings: $50-200/month per GB saved')\n",
    "\n",
    "# Run demonstration\n",
    "demonstrate_ttl_impact()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Right-Sizing Calculator\n",
    "\n",
    "Determine the optimal Redis instance size:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_redis_size(num_keys, avg_value_size_kb, overhead_factor=1.5):\n",
    "    \"\"\"\n",
    "    Estimate required Redis memory\n",
    "    \n",
    "    Args:\n",
    "        num_keys: Number of keys\n",
    "        avg_value_size_kb: Average value size in KB\n",
    "        overhead_factor: Multiplier for Redis overhead (default 1.5 = 50% overhead)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate raw data size\n",
    "    raw_size_mb = (num_keys * avg_value_size_kb) / 1024\n",
    "    \n",
    "    # Add Redis overhead\n",
    "    estimated_mb = raw_size_mb * overhead_factor\n",
    "    \n",
    "    # Add 20% buffer for growth\n",
    "    recommended_mb = estimated_mb * 1.2\n",
    "    \n",
    "    # Suggest tier\n",
    "    tiers = [\n",
    "        ('C0 (250 MB)', 250, 15),\n",
    "        ('C1 (1 GB)', 1024, 55),\n",
    "        ('C2 (2.5 GB)', 2560, 110),\n",
    "        ('C3 (6 GB)', 6144, 239),\n",
    "        ('P1 (6 GB)', 6144, 237),\n",
    "        ('P2 (13 GB)', 13312, 503),\n",
    "        ('P3 (26 GB)', 26624, 1058),\n",
    "    ]\n",
    "    \n",
    "    suggested_tier = None\n",
    "    for tier_name, tier_mb, cost in tiers:\n",
    "        if tier_mb >= recommended_mb:\n",
    "            suggested_tier = (tier_name, cost)\n",
    "            break\n",
    "    \n",
    "    print('üßÆ Redis Size Calculator')\n",
    "    print()\n",
    "    print(f'üìä Your Workload:')\n",
    "    print(f'   Keys: {num_keys:,}')\n",
    "    print(f'   Avg value size: {avg_value_size_kb} KB')\n",
    "    print()\n",
    "    print(f'üíæ Memory Estimates:')\n",
    "    print(f'   Raw data: {raw_size_mb:.1f} MB')\n",
    "    print(f'   With overhead: {estimated_mb:.1f} MB')\n",
    "    print(f'   Recommended: {recommended_mb:.1f} MB (includes 20% growth buffer)')\n",
    "    print()\n",
    "    \n",
    "    if suggested_tier:\n",
    "        print(f'‚úÖ Suggested Tier: {suggested_tier[0]}')\n",
    "        print(f'   Estimated cost: ${suggested_tier[1]}/month')\n",
    "    else:\n",
    "        print('‚ùå Workload exceeds largest tier - consider clustering')\n",
    "\n",
    "# Example 1: Small cache\n",
    "print('Example 1: Small API Cache')\n",
    "estimate_redis_size(num_keys=10000, avg_value_size_kb=2)\n",
    "\n",
    "print('\\n' + '='*60 + '\\n')\n",
    "\n",
    "# Example 2: Session store\n",
    "print('Example 2: Session Store')\n",
    "estimate_redis_size(num_keys=100000, avg_value_size_kb=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Memory Optimization Best Practices\n",
    "\n",
    "### ‚úÖ Do's\n",
    "\n",
    "1. **Use Hashes for objects** - More memory efficient than separate keys\n",
    "2. **Set TTLs on temporary data** - Prevent unbounded growth\n",
    "3. **Monitor memory usage** - Set up alerts at 80% capacity\n",
    "4. **Use appropriate data structures** - Sorted Sets for rankings, Hashes for objects\n",
    "5. **Compress large values** - For values > 100KB\n",
    "\n",
    "### ‚ùå Don'ts\n",
    "\n",
    "1. **Don't store very large values** - Keep values < 1MB\n",
    "2. **Don't use Redis as primary database** - Use as cache/session store\n",
    "3. **Don't skip maxmemory policy** - Set eviction policy\n",
    "4. **Don't ignore fragmentation** - Monitor and address\n",
    "5. **Don't over-provision** - Start small, scale up as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up test data\n",
    "r.flushdb()\n",
    "print('‚úÖ Redis data cleaned')\n",
    "\n",
    "# Stop and remove Docker container\n",
    "!docker stop workshop-redis-module5\n",
    "!docker rm workshop-redis-module5\n",
    "\n",
    "print('‚úÖ Docker container removed')\n",
    "print('‚úÖ Cleanup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "### üí∞ Cost Optimization\n",
    "\n",
    "1. **Right-Size Your Instance**\n",
    "   - Start with smaller tier\n",
    "   - Monitor memory usage\n",
    "   - Scale up only when needed\n",
    "\n",
    "2. **Memory Efficiency**\n",
    "   - Use Hashes instead of separate keys (30-50% savings)\n",
    "   - Set TTLs on cache entries\n",
    "   - Choose appropriate data structures\n",
    "\n",
    "3. **Monitoring**\n",
    "   - Track memory usage trends\n",
    "   - Set alerts at 80% capacity\n",
    "   - Review eviction metrics\n",
    "\n",
    "4. **Cost Calculation**\n",
    "   - Every 1 GB saved = ~$50-80/month\n",
    "   - Proper TTLs can reduce costs by 30-50%\n",
    "   - Right data structures save 20-40% memory\n",
    "\n",
    "### üîß Optimization Checklist\n",
    "\n",
    "- ‚úÖ Set maxmemory and eviction policy\n",
    "- ‚úÖ Use Hashes for multi-field objects\n",
    "- ‚úÖ Set TTLs on all cache keys\n",
    "- ‚úÖ Monitor memory usage\n",
    "- ‚úÖ Regular memory analysis\n",
    "- ‚úÖ Review and optimize key patterns\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Great Job!\n",
    "\n",
    "You now know how to optimize Redis costs and memory usage!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "${workspaceFolder}/.venv/bin/python"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
